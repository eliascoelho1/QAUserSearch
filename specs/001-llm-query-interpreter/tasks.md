# Tasks: Interpretador LLM para Gera√ß√£o de Queries

**Input**: Design documents from `/specs/001-llm-query-interpreter/`
**Prerequisites**: plan.md ‚úì, spec.md ‚úì, research.md ‚úì, data-model.md ‚úì, contracts/ ‚úì

**Tests**: Inclu√≠dos conforme plan.md indica cobertura ‚â•80% e ciclo TDD obrigat√≥rio.

**Organization**: Tasks organizadas por user story para implementa√ß√£o e testes independentes.

## Format: `[ID] [P?] [Story] Description`

- **[P]**: Pode rodar em paralelo (arquivos diferentes, sem depend√™ncias)
- **[Story]**: Qual user story pertence (US1, US2, US3)
- Caminhos exatos inclu√≠dos nas descri√ß√µes

---

## Phase 1: Setup (Infraestrutura Compartilhada)

**Purpose**: Inicializa√ß√£o do projeto e estrutura b√°sica

- [X] T001 Adicionar depend√™ncias openai>=1.0.0 e crewai>=0.80.0 em pyproject.toml
- [X] T002 Executar `uv sync` para instalar novas depend√™ncias
- [X] T003 [P] Criar estrutura de diret√≥rios src/agents/config/
- [X] T004 [P] Criar estrutura de diret√≥rios src/api/v1/websocket/
- [X] T005 [P] Criar estrutura de diret√≥rios src/services/llm/
- [X] T006 [P] Criar estrutura de diret√≥rios src/services/query/
- [X] T007 [P] Criar estrutura de diret√≥rios src/services/audit/
- [X] T008 [P] Criar estrutura de diret√≥rios src/models/query/
- [X] T009 [P] Criar estrutura de diret√≥rios src/schemas/query/
- [X] T010 [P] Criar estrutura de diret√≥rios src/core/security/
- [X] T011 Adicionar vari√°veis OPENAI_API_KEY, OPENAI_MODEL, OPENAI_TIMEOUT, OPENAI_MAX_RETRIES em .env.example

---

## Phase 2: Foundational (Pr√©-requisitos Bloqueantes)

**Purpose**: Infraestrutura core que DEVE estar completa antes de qualquer user story

**‚ö†Ô∏è CR√çTICO**: Nenhuma user story pode come√ßar at√© esta fase estar completa

- [X] T012 [P] Criar enum FilterOperator em src/models/query/enums.py
- [X] T013 [P] Criar enum InterpretationStatus em src/models/query/enums.py
- [X] T014 [P] Criar modelo Entity em src/models/query/interpretation.py
- [X] T015 [P] Criar modelo Filter em src/models/query/interpretation.py
- [X] T016 Criar modelo PromptInterpretation em src/models/query/interpretation.py (depende T014, T015)
- [X] T017 [P] Criar modelo GeneratedQuery em src/models/query/generated_query.py
- [X] T018 [P] Criar modelo QueryResult em src/models/query/query_result.py
- [X] T019 [P] Criar modelo AuditLog em src/models/query/audit_log.py
- [X] T020 Criar migration Alembic para tabela audit_log com √≠ndices em alembic/versions/
- [X] T021 [P] Criar schema InterpretPromptRequest em src/schemas/query/request.py
- [X] T022 [P] Criar schema ExecuteQueryRequest em src/schemas/query/request.py
- [X] T023 [P] Criar schema InterpretationResponse em src/schemas/query/response.py
- [X] T024 [P] Criar schema QueryResponse em src/schemas/query/response.py
- [X] T025 [P] Criar schema QueryResultResponse em src/schemas/query/response.py
- [X] T026 [P] Criar schema ErrorResponse em src/schemas/query/response.py
- [X] T027 [P] Criar schemas WSMessage, WSStatusMessage, WSChunkMessage, WSInterpretationMessage, WSErrorMessage em src/schemas/query/websocket.py
- [X] T028 Criar SQL blacklist FORBIDDEN_COMMANDS com regex em src/core/security/sql_blacklist.py
- [X] T029 Implementar fun√ß√£o validate_query() em src/core/security/sql_blacklist.py
- [X] T030 [P] Criar teste unit√°rio para validate_query() em tests/unit/core/test_sql_blacklist.py
- [X] T031 Criar ConnectionManager para WebSocket em src/api/v1/websocket/connection_manager.py
- [X] T032 [P] Criar teste unit√°rio para ConnectionManager em tests/unit/api/test_connection_manager.py
- [X] T033 Criar OpenAIClient com retry e streaming em src/services/llm/openai_client.py
- [X] T034 [P] Criar teste unit√°rio para OpenAIClient (mock) em tests/unit/services/test_openai_client.py
- [X] T035 Criar CatalogContext para integra√ß√£o com cat√°logo existente em src/services/query/catalog_context.py
- [X] T036 [P] Criar teste unit√°rio para CatalogContext em tests/unit/services/test_catalog_context.py
- [X] T037 Criar agents.yaml com defini√ß√µes de interpreter, validator, refiner em src/agents/config/agents.yaml
- [X] T038 Criar tasks.yaml com defini√ß√µes de tasks do crew em src/agents/config/tasks.yaml

**Checkpoint**: Foundation ready - implementa√ß√£o das user stories pode come√ßar

---

## Phase 3: User Story 1 - Busca por Cen√°rio em Linguagem Natural (Priority: P1) üéØ MVP

**Goal**: Testador QA descreve em linguagem natural e sistema gera query que retorna dados correspondentes

**Independent Test**: Fornecer prompt em linguagem natural e verificar se retorna dados relevantes

### Tests for User Story 1

> **NOTE**: Escrever testes PRIMEIRO, garantir que FALHAM antes da implementa√ß√£o

- [X] T039 [P] [US1] Criar teste de contrato para POST /query/interpret em tests/contract/test_interpret_endpoint.py
- [X] T040 [P] [US1] Criar teste de contrato para POST /query/{id}/execute em tests/contract/test_execute_endpoint.py
- [X] T041 [P] [US1] Criar teste de integra√ß√£o para fluxo prompt ‚Üí query ‚Üí resultado em tests/integration/test_query_flow.py

### Implementation for User Story 1

- [X] T042 [US1] Criar agente PromptInterpreterAgent em src/agents/prompt_interpreter.py
- [X] T043 [US1] Criar agente QueryValidatorAgent em src/agents/query_validator.py
- [X] T044 [US1] Criar agente QueryRefinerAgent em src/agents/query_refiner.py
- [X] T045 [US1] Criar InterpreterCrew com processo sequencial em src/agents/interpreter_crew.py
- [X] T046 [P] [US1] Criar teste unit√°rio para InterpreterCrew em tests/unit/agents/test_interpreter_crew.py
- [X] T047 [US1] Criar InterpreterService (orquestra crew + cat√°logo) em src/services/query/interpreter_service.py
- [X] T048 [P] [US1] Criar teste unit√°rio para InterpreterService em tests/unit/services/test_interpreter_service.py
- [X] T049 [US1] Criar ValidatorService (valida√ß√£o de seguran√ßa SQL) em src/services/query/validator_service.py
- [X] T050 [P] [US1] Criar teste unit√°rio para ValidatorService em tests/unit/services/test_validator_service.py
- [X] T051 [US1] Criar ExecutorService (executa query no banco QA) em src/services/query/executor_service.py
- [X] T052 [P] [US1] Criar teste unit√°rio para ExecutorService em tests/unit/services/test_executor_service.py
- [X] T053 [US1] Criar AuditService (log de queries bloqueadas) em src/services/audit/audit_service.py
- [X] T054 [P] [US1] Criar teste unit√°rio para AuditService em tests/unit/services/test_audit_service.py
- [X] T055 [US1] Implementar endpoint POST /api/v1/query/interpret em src/api/v1/endpoints/query_interpreter.py
- [X] T056 [US1] Implementar endpoint POST /api/v1/query/{query_id}/execute em src/api/v1/endpoints/query_interpreter.py
- [X] T057 [US1] Implementar endpoint GET /api/v1/query/{query_id} em src/api/v1/endpoints/query_interpreter.py
- [X] T058 [US1] Registrar router query_interpreter no app FastAPI em src/main.py
- [X] T059 [US1] Adicionar tratamento de prompts amb√≠guos (ex: "usu√°rios novos" ‚Üí √∫ltimos 30 dias) em src/agents/prompt_interpreter.py
- [X] T060 [US1] Adicionar limite de 100 resultados com flag is_partial em src/services/query/executor_service.py

**Checkpoint**: User Story 1 funcional e test√°vel independentemente - MVP pronto

---

## Phase 4: User Story 2 - Feedback de Interpreta√ß√£o (Priority: P2)

**Goal**: Visualizar como o sistema interpretou o prompt antes de executar, para confirmar ou ajustar

**Independent Test**: Verificar se sistema exibe resumo da interpreta√ß√£o antes de executar

### Tests for User Story 2

- [ ] T061 [P] [US2] Criar teste de integra√ß√£o para WebSocket streaming em tests/integration/test_websocket.py
- [ ] T062 [P] [US2] Criar teste unit√°rio para WSHandlers em tests/unit/api/test_websocket_handlers.py

### Implementation for User Story 2

- [ ] T063 [US2] Criar WebSocket handlers para interpret em src/api/v1/websocket/handlers.py
- [ ] T064 [US2] Implementar streaming de status (interpreting, validating, refining) em src/api/v1/websocket/handlers.py
- [ ] T065 [US2] Implementar streaming de chunks do LLM via WebSocket em src/api/v1/websocket/handlers.py
- [ ] T066 [US2] Implementar endpoint WebSocket /ws/query/interpret em src/api/v1/endpoints/query_interpreter.py
- [ ] T067 [US2] Adicionar campo summary em InterpretationResponse com resumo para usu√°rio em src/schemas/query/response.py
- [ ] T068 [US2] Implementar gera√ß√£o de summary em portugu√™s em src/services/query/interpreter_service.py
- [ ] T069 [US2] Permitir resubmiss√£o de prompt modificado mantendo contexto em src/api/v1/websocket/handlers.py

**Checkpoint**: User Stories 1 e 2 funcionais e test√°veis independentemente

---

## Phase 5: User Story 3 - Tratamento de Erros e Sugest√µes (Priority: P3)

**Goal**: Mensagens claras explicando problemas e sugest√µes de reformula√ß√£o quando prompt falha

**Independent Test**: Fornecer prompts inv√°lidos e verificar se sistema d√° feedback √∫til

### Tests for User Story 3

- [ ] T070 [P] [US3] Criar teste para cen√°rio sem resultados em tests/integration/test_error_handling.py
- [ ] T071 [P] [US3] Criar teste para termos n√£o reconhecidos em tests/integration/test_error_handling.py
- [ ] T072 [P] [US3] Criar teste para query bloqueada (comando proibido) em tests/integration/test_error_handling.py

### Implementation for User Story 3

- [ ] T073 [US3] Implementar mensagens de erro em portugu√™s com sugest√µes em src/schemas/query/response.py
- [ ] T074 [US3] Adicionar detec√ß√£o de termos n√£o reconhecidos no cat√°logo em src/services/query/interpreter_service.py
- [ ] T075 [US3] Adicionar sugest√µes de termos similares do cat√°logo em src/services/query/interpreter_service.py
- [ ] T076 [US3] Implementar mensagem "nenhum resultado" com sugest√µes de crit√©rios mais amplos em src/services/query/executor_service.py
- [ ] T077 [US3] Implementar mensagem detalhada para query bloqueada (qual comando) em src/services/query/validator_service.py
- [ ] T078 [US3] Registrar queries bloqueadas no AuditLog (sem identifica√ß√£o do usu√°rio) em src/services/audit/audit_service.py
- [ ] T079 [US3] Adicionar tratamento de timeout LLM (15s) com mensagem amig√°vel em src/services/llm/openai_client.py
- [ ] T080 [US3] Adicionar tratamento de termos conflitantes (ex: "ativos e inativos") em src/agents/prompt_interpreter.py

**Checkpoint**: Todas as user stories funcionais e test√°veis independentemente

---

## Phase 6: Polish & Cross-Cutting Concerns

**Purpose**: Melhorias que afetam m√∫ltiplas user stories

- [ ] T081 [P] Criar teste de contrato para OpenAI API em tests/contract/test_openai_contract.py
- [ ] T082 [P] Criar teste de contrato para banco de dados QA em tests/contract/test_database_contract.py
- [ ] T083 Adicionar logging estruturado (structlog) em todos os services
- [ ] T084 Adicionar m√©tricas de tempo de resposta (p95) nos services
- [ ] T085 [P] Atualizar documenta√ß√£o em docs/ com exemplos de uso
- [ ] T086 Executar quickstart.md para validar implementa√ß√£o completa
- [ ] T087 Executar pytest --cov=src --cov-report=term-missing e garantir ‚â•80%
- [ ] T088 Executar ruff e black para lint e formata√ß√£o

---

## Dependencies & Execution Order

### Phase Dependencies

- **Setup (Phase 1)**: Sem depend√™ncias - pode come√ßar imediatamente
- **Foundational (Phase 2)**: Depende de Setup - BLOQUEIA todas as user stories
- **User Stories (Phases 3-5)**: Dependem de Foundational
  - Podem prosseguir em paralelo (se equipe permitir)
  - Ou sequencialmente por prioridade (P1 ‚Üí P2 ‚Üí P3)
- **Polish (Phase 6)**: Depende de todas as user stories desejadas

### User Story Dependencies

- **User Story 1 (P1)**: Pode come√ßar ap√≥s Foundational - Sem depend√™ncias de outras stories
- **User Story 2 (P2)**: Pode come√ßar ap√≥s Foundational - Utiliza servi√ßos de US1 mas test√°vel independentemente
- **User Story 3 (P3)**: Pode come√ßar ap√≥s Foundational - Integra com US1/US2 mas test√°vel independentemente

### Within Each User Story

- Testes DEVEM ser escritos e FALHAR antes da implementa√ß√£o (TDD)
- Modelos antes de servi√ßos
- Servi√ßos antes de endpoints
- Implementa√ß√£o core antes de integra√ß√£o
- Story completa antes de mover para pr√≥xima prioridade

### Parallel Opportunities

- Todas as tasks marcadas [P] em Setup podem rodar em paralelo
- Todas as tasks marcadas [P] em Foundational podem rodar em paralelo
- Uma vez Foundational completa, todas as user stories podem come√ßar em paralelo
- Todos os testes de uma user story marcados [P] podem rodar em paralelo
- Modelos dentro de uma story marcados [P] podem rodar em paralelo

---

## Parallel Example: Phase 2 (Foundational)

```bash
# Launch all models in parallel:
Task T012: "Criar enum FilterOperator em src/models/query/enums.py"
Task T013: "Criar enum InterpretationStatus em src/models/query/enums.py"
Task T014: "Criar modelo Entity em src/models/query/interpretation.py"
Task T015: "Criar modelo Filter em src/models/query/interpretation.py"
Task T017: "Criar modelo GeneratedQuery em src/models/query/generated_query.py"
Task T018: "Criar modelo QueryResult em src/models/query/query_result.py"
Task T019: "Criar modelo AuditLog em src/models/query/audit_log.py"

# Launch all schemas in parallel:
Task T021: "Criar schema InterpretPromptRequest em src/schemas/query/request.py"
Task T022: "Criar schema ExecuteQueryRequest em src/schemas/query/request.py"
Task T023: "Criar schema InterpretationResponse em src/schemas/query/response.py"
Task T024: "Criar schema QueryResponse em src/schemas/query/response.py"
Task T025: "Criar schema QueryResultResponse em src/schemas/query/response.py"
Task T026: "Criar schema ErrorResponse em src/schemas/query/response.py"
```

## Parallel Example: User Story 1

```bash
# Launch all tests for User Story 1 together:
Task T039: "Criar teste de contrato para POST /query/interpret"
Task T040: "Criar teste de contrato para POST /query/{id}/execute"
Task T041: "Criar teste de integra√ß√£o para fluxo prompt ‚Üí query ‚Üí resultado"

# Launch all unit tests in parallel (after implementations):
Task T046: "Criar teste unit√°rio para InterpreterCrew"
Task T048: "Criar teste unit√°rio para InterpreterService"
Task T050: "Criar teste unit√°rio para ValidatorService"
Task T052: "Criar teste unit√°rio para ExecutorService"
Task T054: "Criar teste unit√°rio para AuditService"
```

---

## Implementation Strategy

### MVP First (User Story 1 Only)

1. Complete Phase 1: Setup
2. Complete Phase 2: Foundational (CR√çTICO - bloqueia todas as stories)
3. Complete Phase 3: User Story 1
4. **STOP and VALIDATE**: Testar User Story 1 independentemente
5. Deploy/demo se pronto

### Incremental Delivery

1. Complete Setup + Foundational ‚Üí Foundation ready
2. Add User Story 1 ‚Üí Test independentemente ‚Üí Deploy/Demo (MVP!)
3. Add User Story 2 ‚Üí Test independentemente ‚Üí Deploy/Demo
4. Add User Story 3 ‚Üí Test independentemente ‚Üí Deploy/Demo
5. Cada story adiciona valor sem quebrar stories anteriores

### Parallel Team Strategy

Com m√∫ltiplos desenvolvedores:

1. Equipe completa Setup + Foundational juntos
2. Uma vez Foundational pronto:
   - Developer A: User Story 1
   - Developer B: User Story 2
   - Developer C: User Story 3
3. Stories completam e integram independentemente

---

## Notes

- [P] tasks = arquivos diferentes, sem depend√™ncias
- [Story] label mapeia task para user story espec√≠fica para rastreabilidade
- Cada user story deve ser complet√°vel e test√°vel independentemente
- Verificar que testes falham antes de implementar
- Commit ap√≥s cada task ou grupo l√≥gico
- Pare em qualquer checkpoint para validar story independentemente
- Evitar: tasks vagas, conflitos de mesmo arquivo, depend√™ncias cross-story que quebram independ√™ncia
